\section{conclusion}

As can be seen in the performance section, a simple logistic regression seems to be performing the best. However, it is possible to achieve small improvement by adding extra features, but this is not significant. 

Adding different parts of the \textit{bypublisher} dataset, makes the results worse. This might have something to do with the fact that the classifier will not be trained on hyperpartisian, but on the publisher itself. So combining two different training specifications is actually a bad idea. 

The CNN's using this research are hard to apply, something that is easily under-estimated. 

At last, it turned out that a lot of resources are needed. A simple laptop with 16 GB of RAM is not enough to run the algorithms on a dataset which is larger than one gigabyte.